{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyME8Zl7cbu4mXEzD40IuFo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanzee23/Convolution-Neural-Netwrok-using-Keras/blob/main/MNIST_CNN_Keras_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# CNN Model using Keras.\n",
        "\n",
        "This notebook is associated with implementation of cnn model using keras. The model is trained and tested upon MNIST data set.\n",
        "\n",
        "Below is the list of performed steps in achieving the working CNN Model:\n",
        "\n",
        "* Import Data\n",
        "* Preprocess Data\n",
        "    1. Refactorization\n",
        "    2. Normalization\n",
        "* Model Structure\n",
        "    1. Convolation Layer\n",
        "    2. Pooling Layer\n",
        "* Model Training\n",
        "* Model Testing\n",
        "* Model Status\n",
        "\n",
        "*Before working with code its highly recommended to view read me file*\n"
      ],
      "metadata": {
        "id": "u9GBlUlEKlna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for various useful utilities\n",
        "\n",
        "import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "AmmIxMGr-5ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Checkpoint A*\n",
        "\n",
        "Checkpoint after importing all the desired Packages and Libraries.\n",
        "\n",
        "Steps for next checkpoint.\n",
        "1. Load Data\n",
        "2. Normalize input dataset samples accross the board.\n",
        "3. Make one hot encoded vector."
      ],
      "metadata": {
        "id": "44iUEIPyKsWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load_Data function, loads the required mnist dataset for model training and testing,\n",
        "# while also performing data preprocessing for model compatiblity.\n",
        "\n",
        "def Load_Data():\n",
        "\n",
        "  # Download and load MNIST Dataset from keras builtin datasets\n",
        "  ( Train_X, Train_Y ), ( Test_X, Test_Y ) = keras.datasets.mnist.load_data()\n",
        "\n",
        "  # Reshape Dataset to have one single channel\n",
        "  Train_X = Train_X.reshape( Train_X.shape[0], 28, 28, 1 )\n",
        "  Test_X = Test_X.reshape( Test_X.shape[0], 28, 28, 1 )\n",
        "\n",
        "  # Normalize input datasamples within range [0-1]\n",
        "  Train_X = ( Train_X.astype('float32') ) / 225.0\n",
        "  Test_X = ( Test_X.astype('float32') ) / 225.0\n",
        "\n",
        "  # Make one hot encoded verctor for true labels\n",
        "  Train_Y = to_categorical( Train_Y )\n",
        "  Test_Y = to_categorical( Test_Y )\n",
        "\n",
        "  # Return Preprocessed Data\n",
        "  return ( Train_X, Train_Y ), ( Test_X, Test_Y )"
      ],
      "metadata": {
        "id": "wBu41j7NMEf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code block is for testing above code snippet\n",
        "\n",
        "( Train_X, Train_Y ), ( Test_X, Test_Y ) = Load_Data()\n",
        "\n",
        "print( Train_X.shape, Train_Y.shape )\n",
        "print( Test_X.shape, Test_Y.shape )"
      ],
      "metadata": {
        "id": "co_WrFmQ1mr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Checkpoint B*\n",
        "\n",
        "Checkpoint after loading the dataset and performing all required data pre-processing steps on MNIST Dataset.\n",
        "\n",
        "Steps for next checkpoint:\n",
        "1. keras sequential model creation"
      ],
      "metadata": {
        "id": "YUwvPWarKHOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "# ML_Model function, returns keras sequential cnn model,\n",
        "# which consists of defined layers and model attributes.\n",
        "\n",
        "def ML_Model( ):\n",
        "\n",
        "  model = keras.Sequential()    # Creates keras sequential model object.\n",
        "\n",
        "  model.add( layers.Input( shape = Train_X[0].shape ) )   # Adds Input layer defining the shape of provided input.\n",
        "\n",
        "  # Adds first convolution layer having 10 different filters each of size 3x3x1 and max pool layer of size 2x2x1,\n",
        "  # where stride is one for both\n",
        "  model.add( layers.Conv2D( 10, (3, 3), activation = \"relu\", use_bias = True, kernel_initializer = \"he_uniform\" ) )\n",
        "  model.add( layers.MaxPooling2D( (2, 2), (1, 1), padding = \"valid\" ) )\n",
        "\n",
        "  # Adds second convolution layer having 10 different filters each of size 2x2x1 and max pool layer of size 2x2x1,\n",
        "  # where stride is one for both\n",
        "  model.add( layers.Conv2D( 10, (2, 2), activation = \"relu\", use_bias = True, kernel_initializer = \"he_uniform\" ) )\n",
        "  model.add( layers.MaxPooling2D( (2, 2), (1, 1), padding = \"valid\" ) )\n",
        "\n",
        "  # Extend the output from previous layer.\n",
        "  model.add( layers.Flatten( ) )\n",
        "\n",
        "  # Adds a fully connected layer, having 15 neurons.\n",
        "  model.add( layers.Dense( 15, activation = \"relu\", use_bias = True, kernel_initializer = \"he_normal\" ) )\n",
        "\n",
        "  # Adds second fully connected layer, having 10 neurons, which will predict data.\n",
        "  model.add( layers.Dense( 10, activation = \"softmax\", use_bias = True, kernel_initializer = \"he_normal\" ) )\n",
        "\n",
        "  # Select desired optimizer and loss for model.\n",
        "  m_optim = optimizers.SGD( learning_rate = 0.01 )\n",
        "  m_loss = losses.CategoricalCrossentropy( )\n",
        "\n",
        "  # Complie your built model for training and testing.\n",
        "  model.compile( m_optim, m_loss, metrics = [ \"accuracy\" ] )\n",
        "\n",
        "  # Return the constructed model.\n",
        "  return model"
      ],
      "metadata": {
        "id": "aMI1YW2-4Mt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code snippet is used to view model summary\n",
        "\n",
        "myModel = ML_Model()\n",
        "myModel.summary()"
      ],
      "metadata": {
        "id": "NCb7QsRmJjS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Checkpoint C*\n",
        "\n",
        "Checkpoint after keras sequential cnn model creation and verification.\n",
        "\n",
        "Steps for next checkpoint:\n",
        "1. Training the model\n",
        "2. Testing the model"
      ],
      "metadata": {
        "id": "Gb5b2vcqMOZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train complied model on provided training dataset, in defined batch_size ( 32 by default ) and epohs\n",
        "\n",
        "history = myModel.fit( Train_X, Train_Y, epochs = 5 )\n",
        "print( history.history )    # returns dictionary containing info of loss and specified metrics, for defined number of epochs"
      ],
      "metadata": {
        "id": "TbJ9Lh76Mkeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test complied model on given testing dataset and generate results of model performance\n",
        "\n",
        "results = myModel.evaluate( Test_X, Test_Y )\n",
        "print( results )    # returns loss and value for specified metrics"
      ],
      "metadata": {
        "id": "Qn3vkYcaeh5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Checkpoint D*\n",
        "Checkpoint after model training and testing\n",
        "\n",
        "Steps for next Checkpoint:\n",
        "1. Evaluate and print model status *( like accuracy, predictions )*\n",
        "2. Visualization of the model prediction via graph *( if possible )*"
      ],
      "metadata": {
        "id": "-tP1un5jlvRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask model to generante predictions on completetly annonymous data sample.\n",
        "\n",
        "predictions = myModel.predict( Train_X[ :10 ] )     # Selecting first 10 sample from train data for testing model predictions\n",
        "true_label = [ np.argmax( sample ) for sample in Train_Y ]    # Extracting true labels of selected data sampels\n",
        "\n",
        "max_score = np.max( predictions, axis = 1 )       # maximum score for specific class (prediction)\n",
        "pred_label = np.argmax( predictions, axis = 1 )   # label of predicted class\n",
        "\n",
        "for res in range( 10 ):\n",
        "  print( \"Serial No. \", ( res + 1 ), \"\\nMax Score: \", max_score[res], \"\\nPredicted Label: \", pred_label[res], \"\\nTrue Label: \", true_label[res], end = \"\\n\\n\" )"
      ],
      "metadata": {
        "id": "N4b66HC5mS5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Data Sample Display*\n",
        "\n",
        "* The following code help achieve pictorial  view of few selected samples from train and test dataset samples.\n",
        "\n",
        "* The following code is not responsible for model creation, training and testing.\n",
        "\n",
        "* The following code is just for help and understanding purposes."
      ],
      "metadata": {
        "id": "W2w9qrWN6zau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following code is direct copied from a source, the code displays first 10 images of test dataset.\n",
        "\n",
        "# importing utilites\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# graph object selections\n",
        "num = 10\n",
        "images = Test_X[:10]\n",
        "labels = Test_Y[:10]\n",
        "\n",
        "labels = [ np.argmax(label) for label in labels ]\n",
        "\n",
        "num_row = 2\n",
        "num_col = 5\n",
        "\n",
        "# plot images\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DlvST1KHiHEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Following code is directly copied from a source and display only one selected image\n",
        "\n",
        "train_sample = Train_X[0].copy()  # selecting any random datset sample\n",
        "\n",
        "# display the selected image\n",
        "fig = plt.figure\n",
        "plt.imshow( train_sample, cmap = 'gray' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "01ptQiM76RJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}